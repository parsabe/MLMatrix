{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ea0f441",
   "metadata": {},
   "source": [
    "# Mathematics of Machine Learning\n",
    "## Chapter 2: Linear predictors\n",
    "### Section 2.1: The Perceptron algorithm\n",
    "\n",
    "#### Python script to reproduce the example of the perceptron algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed38a682",
   "metadata": {},
   "source": [
    "#### Preliminaries\n",
    "(a) Loading required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e482642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy  # for optimization algorithm\n",
    "import matplotlib\n",
    "# change font size for all matplotlib plots\n",
    "matplotlib.rc('font', size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e5f27",
   "metadata": {},
   "source": [
    "(b) Implementing the perceptron algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9624dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_perceptron(x, y, b=1, n_iter=int(1e6), rng=np.random.default_rng(seed=42)):\n",
    "    \"\"\"\n",
    "    This function executes the perceptron algorithm from section 3.1.\n",
    "\n",
    "    By means of the third (optional) argument it shall be distinguished whether a homogeneous linear hypothesis \n",
    "    is to be learned or not.\n",
    "\n",
    "    :param x:      (d, m)-Matrix consisting of the m training features in R^d\n",
    "    :param y:      (m)-Vector consisting of the m associated labels {-1, +1}\n",
    "    :param b:      Optional argument that learns a homogeneous linear hypothesis from the data for the value 0, \n",
    "                   otherwise a general linear   hypothesis\n",
    "    :param n_iter: Maximum number of interations for the algorithm (by default infinity)\n",
    "\n",
    "    :returns:\n",
    "      - w     Vector containing the learned weights and bias in the form (w_1, w_2, ... w_d, b)\n",
    "      - T     Integer of the number of executed steps in the algorithm\n",
    "      - ws    Matrix with T+1 columns, the t-th column contains the t-th step Iterated of the procedure\n",
    "      - RSs   Row vector containing the empirical risk for each vector ws\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Reading the dimension d and the data number m from x and y, respectively.\n",
    "    d = x.shape[0]\n",
    "    m = y.shape[0]\n",
    "\n",
    "    # Case discrimination, whether homogeneous hypothesis should be learned\n",
    "    xb = np.append(x, np.ones((1, m)), axis=0) if b==1 else x\n",
    "\n",
    "    # Function to check the constraints\n",
    "    check = lambda w, xb, y, m: y * (w @ xb)\n",
    "\n",
    "    # Calculation of the obtained empirical risk\n",
    "    RS = lambda chk: np.mean(chk <= 0)\n",
    "\n",
    "    # Initialize extended weight vector\n",
    "    w = np.zeros(d+b)\n",
    "    # First entry in ws:\n",
    "    ws = [ w ]\n",
    "    # Empirical risk of the current w:\n",
    "    RSs = [ RS(check(w, xb, y, m)) ]\n",
    "    # Iteration variable of while loop\n",
    "    t = 0\n",
    "    while np.min(check(w, xb, y, m)) <= 0 and t < n_iter:\n",
    "        # Find all unsatisfied constraints\n",
    "        ... \n",
    "        \n",
    "        # Select an unfulfilled constraint\n",
    "        i = rng.choice( ... )\n",
    "        \n",
    "        # Update according to iteration rule\n",
    "        ...        \n",
    "              \n",
    "        # Save current w in ws\n",
    "        ws.append(w)\n",
    "\n",
    "        # Calculate empirical risk and store in RSs\n",
    "        RSs.append( RS(check(w, xb, y, m)) )\n",
    "\n",
    "        # Increase step counter\n",
    "        t += 1\n",
    "\n",
    "    return [w, t, np.array(ws), np.array(RSs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d01ae4",
   "metadata": {},
   "source": [
    "#### (0) Preparation\n",
    "Generate the training data $x,y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of data\n",
    "m = 25\n",
    "rng = np.random.default_rng(seed=42) # initialising RNG\n",
    "x = rng.uniform(low=-3, high=3, size=(2, m))  # each x in U[-3, 3)\n",
    "\n",
    "# true separating hyperplane\n",
    "w_true = np.array([1, 2])\n",
    "\n",
    "# The sign function returns -1 if x < 0, 0 if x==0, 1 if x > 0. nan is returned for nan inputs.\n",
    "y = np.sign(w_true @ x) + ((w_true @ x) == 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdafc98",
   "metadata": {},
   "source": [
    "Plot the training data: First plot the true hyperplane for $x \\in [-3,3]$, then add the classified points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743218a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices of points with mark 1\n",
    "inds = np.where(y==1)\n",
    "\n",
    "# indices of points with mark -1\n",
    "indm = np.where(y==-1)\n",
    "\n",
    "# First plot the true hyperplane for x in [-3,3].\n",
    "fig, ax = plt.subplots()\n",
    "xvec = np.array([-3, 3])\n",
    "yvec = -w_true[0]/w_true[1]*xvec\n",
    "ax.plot(xvec, yvec, \"--\", label=\"true hyperplane\")\n",
    "\n",
    "# Then add the training data points according to its label\n",
    "ax.scatter(x[0][inds], x[1][inds], c=\"b\", marker=\"+\", linewidths = 2)\n",
    "ax.scatter(x[0][indm], x[1][indm], c=\"r\", marker=\"d\", linewidths = 2)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"$x_1$\")\n",
    "ax.set_ylabel(\"$x_2$\")\n",
    "ax.set(xlim=(-3, 3), ylim=(-3, 3))\n",
    "ax.grid(linestyle='dotted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cfcc28",
   "metadata": {},
   "source": [
    "#### (2) Run the Perceptron algorithm for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e7c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the algorithm to the data with b = 0 fixed.\n",
    "[w, T, ws, RSs] = my_perceptron(x=x, y=y, b=0, n_iter=10000, rng=np.random.default_rng(seed=42))\n",
    "\n",
    "# Print number of iterations\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718422f4",
   "metadata": {},
   "source": [
    "Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee66b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting true and learned hyperplane for x in [-3,3].\n",
    "fig, ax = plt.subplots()\n",
    "xvec = np.array([-3, 3])\n",
    "yvec_true = -w_true[0]/w_true[1]*xvec\n",
    "yvec = -w[0]/w[1]*xvec\n",
    "ax.plot(xvec, yvec_true, \"--\", label=\"true hyperplane\")\n",
    "\n",
    "ax.plot(xvec, yvec, \"g\", label=\"learned hypothesis\")\n",
    "\n",
    "ax.scatter(x[0][inds], x[1][inds], c=\"b\", marker=\"+\", linewidths = 2)\n",
    "ax.scatter(x[0][indm], x[1][indm], c=\"r\", marker=\"_\", linewidths = 2)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"$x_1$\")\n",
    "ax.set_ylabel(\"$x_2$\")\n",
    "ax.set(xlim=(-3, 3), ylim=(-3, 3))\n",
    "ax.grid(linestyle='dotted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1321b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting iterates of Perceptron algorithm\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Calculating the solution cone\n",
    "A = np.tile(y, (2, 1)) * x\n",
    "indAn = np.where(A[1,:]<0)\n",
    "indAp = np.where(A[1,:]>0)\n",
    "a_low = np.max(-A[0, indAp]/A[1, indAp])\n",
    "a_up = np.min(-A[0, indAn]/A[1, indAn])\n",
    "area_x = [0, 6, 6, 0]\n",
    "area_y = [0, 6*a_low, 6*a_up, 0]\n",
    "\n",
    "# Plotting\n",
    "ax.fill(area_x, area_y, color='lime', label='solution set')\n",
    "ax.plot(ws[:,0], ws[:,1], 'o-k', label='iterates of perceptron')\n",
    "ax.set_xlabel(\"$w_1$\")\n",
    "ax.set_ylabel(\"$w_2$\")\n",
    "ax.grid(linestyle='dotted')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
